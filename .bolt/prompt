The Plan
Supabase Database Update for Conversation Sessions:

File: This will involve a database migration.
Description: Create a new table named conversation_sessions to store the state and history of each real-time conversation. This is crucial for maintaining context across turns and for features like interruption.
Why: To persist conversation history, user medical context, and session status, allowing for seamless, multi-turn interactions and recovery from disconnections.
Backend WebSocket Server Implementation:

File: You will need to create new files, for example, backend/routes/conversationWebSocket.js for REST endpoints to initiate sessions, and backend/websocket/conversationHandler.js for the actual WebSocket logic. You'll also need to integrate the WebSocket server into backend/server.js.
Description: Set up a WebSocket server that the frontend can connect to. This server will handle real-time audio streams from the user and stream back AI-generated audio responses.
Implement a REST endpoint (e.g., POST /api/conversation/start) to initiate a new conversation session and return a WebSocket URL.
Implement the WebSocket connection handler to receive audio chunks from the frontend.
Why: To enable continuous, low-latency, bidirectional communication required for natural conversational AI, moving beyond the current turn-based request-response model.
Integrate STT, RAG, and TTS into WebSocket Flow:

File: Primarily within backend/websocket/conversationHandler.js and potentially backend/lib/services/TxAgentRAGService.js for prompt refinement.
Description: Within the WebSocket handler:
Receive incoming audio chunks from the user.
Use your existing Speech-to-Text (STT) functionality (e.g., by calling the OpenAI Whisper API directly or via your /api/voice/transcribe endpoint) to transcribe the audio into text.
Pass the transcribed text to your TxAgentRAGService.performRAG function to retrieve relevant medical documents and generate an augmented query.
Send this augmented query to your TxAgent container's chat endpoint to get the AI's response.
Use your existing Text-to-Speech (TTS) functionality (e.g., by calling the ElevenLabs API directly or via your /api/voice/tts endpoint) to convert the AI's text response into audio.
Stream the generated audio back to the frontend via the WebSocket connection.
Why: This is the core of the real-time conversational AI, connecting all the pieces: voice input, RAG-enhanced intelligence, and voice output.
Implement Conversation Session Management Logic:

File: Within backend/websocket/conversationHandler.js and potentially a new service like backend/services/ConversationSessionService.js.
Description: Manage the conversation_sessions table:
When a session starts, create a new entry.
Update the session's conversation_history with each turn of dialogue (user query and AI response).
Store and retrieve the user's medical_profile and other relevant context from the session.
Why: To provide the AI with memory of the ongoing conversation and access to the user's profile, enabling more personalized and coherent interactions.
Integrate AI Behavior (from your Spec) into Backend Logic:

File: Primarily backend/lib/services/TxAgentRAGService.js (for createAugmentedPrompt) and potentially backend/routes/medicalConsultation.js (for emergency detection).
Description: Ensure your AI's responses adhere to the "Symptom Savior Conversational Agent Spec":
Disclaimer: Modify the prompt construction in TxAgentRAGService.createAugmentedPrompt to always include the disclaimer at the start of the AI's response.
Emergency Redirection: Integrate the emergency detection logic into the WebSocket flow. If an emergency is detected, immediately send the emergency response and interrupt any ongoing AI speech.
Tone and Goal: Refine the system prompts and instructions passed to the TxAgent to guide its tone (professional, empathetic) and ensure it focuses on information retrieval and question answering based on provided documents.
Guardrails: Reinforce the guardrails (e.g., "use only provided documents," "never give emergency advice") within the system prompts.
Why: To ensure the AI behaves as intended, providing safe, helpful, and contextually appropriate responses.
This plan directly addresses the high-priority items identified in the CONVO_AI_UPGRADE.md and integrates your AI agent specification into the backend's operational logic.